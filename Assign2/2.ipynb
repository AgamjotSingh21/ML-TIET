{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48310184-8a22-4196-9eda-deab4218675e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Similarity Calculations for Object 1 and Object 2 ---\n",
      "Simple Matching Coefficient (SMC): 0.8750\n",
      "Jaccard Similarity: 0.6000\n",
      "Cosine Similarity: -0.1295\n",
      "\n",
      "--- Correlation Analysis ---\n",
      "Pearson Correlation between 'NumberCarsOwned' (proxy for Commute Distance) and 'YearlyIncome': 0.4773\n"
     ]
    }
   ],
   "source": [
    "# Part I: Based on Feature Selection, Cleaning, and Preprocessing to Construct an Input from Data Source\n",
    "# (a) Examine the values of each attribute and Select a set of attributes only that would affect to predict\n",
    "#     future bike buyers to create your input for data mining algorithms. Remove all the unnecessary\n",
    "#     attributes. (Select features just by analysis).\n",
    "# (b) Create a new Data Frame with the selected attributes only.\n",
    "# (c) Determine a Data value type (Discrete, or Continuous, then Nominal, Ordinal, Interval, Ratio) of\n",
    "#     each attribute in your selection to identify preprocessing tasks to create input for your data mining.\n",
    "\n",
    "# Part II: Data Preprocessing and Transformation\n",
    "# Depending on the data type of each attribute, transform each object from your preprocessed data.\n",
    "# Use all the data rows (~18000 rows) with the selected features as input to apply all the tasks below, do\n",
    "# not perform each task on the smaller data set that you got from your random sampling result.\n",
    "# (a) Handling Null values\n",
    "# (b) Normalization\n",
    "# (c) Discretization (Binning) on Continuous attributes or Categorical Attributes with too many different\n",
    "#     values\n",
    "# (d) Standardization/Normalization\n",
    "# (e) Binarization (One Hot Encoding)\n",
    "\n",
    "# Part III: Calculating Proximity/Correlation Analysis of two features\n",
    "# Make sure each attribute is transformed in a same scale for numeric attributes and Binarization for each\n",
    "# nominal attribute, and each discretized numeric attribute to standardization. Make sure to apply a correct\n",
    "# similarity measure for nominal (one hot encoding)/binary attributes and numeric attributes respectively.\n",
    "# (a) Calculate Similarity in Simple Matching, Jaccard Similarity, and Cosine Similarity between two\n",
    "#     following objects of your transformed input data.\n",
    "# (b) Calculate Correlation between two features Commute Distance and Yearly Income\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder, OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# --- Load Datasets ---\n",
    "# Assuming the CSV files are uploaded and accessible in the Colab environment.\n",
    "# Replace with the actual file paths if they are different.\n",
    "try:\n",
    "    customers_df = pd.read_csv('AWCustomers.csv')\n",
    "    sales_df = pd.read_csv('AWSales.csv')\n",
    "    # Test files are not used in this assignment based on the prompt's scope,\n",
    "    # but are included here for completeness if needed for future tasks.\n",
    "    # test_classification_df = pd.read_csv('AWTest-Classification.csv')\n",
    "    # test_regression_df = pd.read_csv('AWTest-Regression.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Ensure 'AWCustomers.csv' and 'AWSales.csv' are uploaded to your Colab environment.\")\n",
    "    exit()\n",
    "\n",
    "# --- Part I: Feature Selection, Cleaning, and Preprocessing Input Construction ---\n",
    "\n",
    "# Merge the two dataframes on CustomerID\n",
    "df_merged = pd.merge(customers_df, sales_df, on='CustomerID', how='inner')\n",
    "\n",
    "# (a) & (b) Select relevant attributes and create a new DataFrame\n",
    "# Attributes selected for predicting bike buyers:\n",
    "# - BirthDate (will be converted to Age)\n",
    "# - Education (Ordinal)\n",
    "# - Occupation (Nominal)\n",
    "# - Gender (Nominal)\n",
    "# - MaritalStatus (Nominal)\n",
    "# - HomeOwnerFlag (Binary/Discrete)\n",
    "# - NumberCarsOwned (Discrete/Ratio)\n",
    "# - NumberChildrenAtHome (Discrete/Ratio)\n",
    "# - TotalChildren (Discrete/Ratio)\n",
    "# - YearlyIncome (Continuous/Ratio)\n",
    "# - CountryRegionName (Nominal - broader geographical indicator)\n",
    "# - AvgMonthSpend (Continuous/Ratio - historical spend)\n",
    "# - BikeBuyer (Target variable - Binary)\n",
    "\n",
    "selected_features = [\n",
    "    'BirthDate', 'Education', 'Occupation', 'Gender', 'MaritalStatus',\n",
    "    'HomeOwnerFlag', 'NumberCarsOwned', 'NumberChildrenAtHome',\n",
    "    'TotalChildren', 'YearlyIncome', 'CountryRegionName', 'AvgMonthSpend', 'BikeBuyer'\n",
    "]\n",
    "\n",
    "df_selected = df_merged[selected_features].copy()\n",
    "\n",
    "# (c) Determine Data Value Type of each attribute\n",
    "# This is described in comments for each feature during preprocessing steps.\n",
    "\n",
    "# --- Part II: Data Preprocessing and Transformation ---\n",
    "\n",
    "# 1. Convert BirthDate to Age\n",
    "df_selected['BirthDate'] = pd.to_datetime(df_selected['BirthDate'])\n",
    "current_year = pd.to_datetime('2017-03-06').year # Using a reference date from LastUpdated column\n",
    "df_selected['Age'] = current_year - df_selected['BirthDate'].dt.year\n",
    "df_selected.drop('BirthDate', axis=1, inplace=True)\n",
    "\n",
    "# 2. (a) Handling Null values\n",
    "# Check for nulls\n",
    "# print(\"Null values before imputation:\\n\", df_selected.isnull().sum())\n",
    "\n",
    "# Impute 'Education', 'Occupation', 'Gender', 'MaritalStatus', 'CountryRegionName' with mode\n",
    "# Impute numerical columns 'Age', 'YearlyIncome', 'AvgMonthSpend', 'NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren' with median\n",
    "categorical_cols_to_impute = ['Education', 'Occupation', 'Gender', 'MaritalStatus', 'CountryRegionName']\n",
    "numerical_cols_to_impute = ['Age', 'YearlyIncome', 'AvgMonthSpend', 'NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren', 'HomeOwnerFlag'] # HomeOwnerFlag is also discrete\n",
    "\n",
    "for col in categorical_cols_to_impute:\n",
    "    if df_selected[col].isnull().any():\n",
    "        mode_val = df_selected[col].mode()[0]\n",
    "        df_selected[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "for col in numerical_cols_to_impute:\n",
    "    if df_selected[col].isnull().any():\n",
    "        median_val = df_selected[col].median()\n",
    "        df_selected[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# Convert HomeOwnerFlag to int (it's already 0 or 1 but ensure type)\n",
    "df_selected['HomeOwnerFlag'] = df_selected['HomeOwnerFlag'].astype(int)\n",
    "df_selected['BikeBuyer'] = df_selected['BikeBuyer'].astype(int)\n",
    "\n",
    "\n",
    "# (b) Normalization & (d) Standardization/Normalization\n",
    "# This will be applied after other transformations, typically StandardScaler for continuous,\n",
    "# and OneHotEncoder for nominals puts them on a scale (0 or 1).\n",
    "# For now, define the types:\n",
    "\n",
    "# (c) Discretization (Binning) on Continuous attributes or Categorical Attributes with too many different values\n",
    "# Bin 'Age', 'YearlyIncome', 'AvgMonthSpend' into 5 bins\n",
    "numerical_for_binning = ['Age', 'YearlyIncome', 'AvgMonthSpend']\n",
    "for col in numerical_for_binning:\n",
    "    if df_selected[col].dtype == 'object': # Convert to numeric if not already\n",
    "        df_selected[col] = pd.to_numeric(df_selected[col], errors='coerce')\n",
    "        # Re-impute if new NaNs were created by coercion\n",
    "        if df_selected[col].isnull().any():\n",
    "            df_selected[col].fillna(df_selected[col].median(), inplace=True)\n",
    "\n",
    "    discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform') # or 'quantile'\n",
    "    # Reshape for KBinsDiscretizer which expects 2D array\n",
    "    df_selected[f'{col}_Binned'] = discretizer.fit_transform(df_selected[[col]])\n",
    "    df_selected.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# (e) Binarization (One Hot Encoding) for nominal attributes\n",
    "nominal_cols = ['Occupation', 'Gender', 'MaritalStatus', 'CountryRegionName']\n",
    "ordinal_cols = ['Education'] # Education is ordinal, will use OrdinalEncoder\n",
    "\n",
    "# Define ordinal categories for Education\n",
    "education_order = ['Partial High School', 'High School', 'Partial College', 'Bachelors', 'Graduate Degree']\n",
    "encoder_education = OrdinalEncoder(categories=[education_order], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "df_selected['Education_Encoded'] = encoder_education.fit_transform(df_selected[['Education']])\n",
    "df_selected.drop('Education', axis=1, inplace=True)\n",
    "\n",
    "# One-Hot Encode nominal features\n",
    "encoder_ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "ohe_features = encoder_ohe.fit_transform(df_selected[nominal_cols])\n",
    "ohe_feature_names = encoder_ohe.get_feature_names_out(nominal_cols)\n",
    "df_ohe = pd.DataFrame(ohe_features, columns=ohe_feature_names, index=df_selected.index)\n",
    "df_selected = pd.concat([df_selected.drop(nominal_cols, axis=1), df_ohe], axis=1)\n",
    "\n",
    "# (d) Standardization/Normalization for numerical features\n",
    "# After binning and one-hot encoding, apply StandardScaler to remaining numerical columns.\n",
    "# These include 'NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren', 'HomeOwnerFlag',\n",
    "# 'Education_Encoded', and the newly binned columns.\n",
    "# The target 'BikeBuyer' is binary and should not be scaled for classification.\n",
    "\n",
    "numerical_for_scaling = [col for col in df_selected.columns if col not in ['BikeBuyer'] and df_selected[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Exclude one-hot encoded columns from standard scaling if they are already 0/1.\n",
    "# The prompt says \"Make sure each attribute is transformed in a same scale for numeric attributes and\n",
    "# Binarization for each nominal attribute, and each discretized numeric attribute to standardization.\"\n",
    "# This implies that binarized (OHE) attributes are fine as they are (0 or 1),\n",
    "# and numerical/discretized ones should be standardized.\n",
    "\n",
    "final_numerical_cols = ['NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren',\n",
    "                        'HomeOwnerFlag', 'Education_Encoded',\n",
    "                        'Age_Binned', 'YearlyIncome_Binned', 'AvgMonthSpend_Binned']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_selected[final_numerical_cols] = scaler.fit_transform(df_selected[final_numerical_cols])\n",
    "\n",
    "# Final preprocessed DataFrame\n",
    "df_preprocessed = df_selected.copy()\n",
    "# print(\"\\nPreprocessed DataFrame head:\\n\", df_preprocessed.head())\n",
    "# print(\"\\nPreprocessed DataFrame info:\\n\")\n",
    "# df_preprocessed.info()\n",
    "\n",
    "# --- Part III: Calculating Proximity/Correlation Analysis of two features ---\n",
    "\n",
    "# (a) Calculate Similarity in Simple Matching, Jaccard Similarity, and Cosine Similarity\n",
    "# between two objects of your transformed input data.\n",
    "\n",
    "# Select two arbitrary objects (rows) from the preprocessed data.\n",
    "object1 = df_preprocessed.iloc[0]\n",
    "object2 = df_preprocessed.iloc[1]\n",
    "\n",
    "# Separate binary/nominal (one-hot encoded) features and numerical (scaled) features\n",
    "# for similarity calculations.\n",
    "# One-hot encoded features are those that start with the nominal column prefix + '_'\n",
    "# and the HomeOwnerFlag (which is binary).\n",
    "binary_nominal_features = [col for col in df_preprocessed.columns if col.startswith(('Occupation_', 'Gender_', 'MaritalStatus_', 'CountryRegionName_')) or col == 'HomeOwnerFlag']\n",
    "numerical_features_for_cosine = [col for col in df_preprocessed.columns if col not in binary_nominal_features and col != 'BikeBuyer']\n",
    "\n",
    "obj1_binary_nominal = object1[binary_nominal_features].values\n",
    "obj2_binary_nominal = object2[binary_nominal_features].values\n",
    "\n",
    "obj1_numerical_cosine = object1[numerical_features_for_cosine].values\n",
    "obj2_numerical_cosine = object2[numerical_features_for_cosine].values\n",
    "\n",
    "# Simple Matching Coefficient (SMC)\n",
    "# SMC = (number of matching attributes) / (total of attributes)\n",
    "# Manual implementation for SMC\n",
    "matching_attributes = np.sum(obj1_binary_nominal == obj2_binary_nominal)\n",
    "total_attributes = len(obj1_binary_nominal)\n",
    "smc = matching_attributes / total_attributes if total_attributes > 0 else 0\n",
    "\n",
    "print(f\"\\n--- Similarity Calculations for Object 1 and Object 2 ---\")\n",
    "print(f\"Simple Matching Coefficient (SMC): {smc:.4f}\")\n",
    "\n",
    "\n",
    "# Ensure inputs are 1D arrays for jaccard_score if they're not already\n",
    "obj1_binary_nominal_1d = np.squeeze(obj1_binary_nominal)\n",
    "obj2_binary_nominal_1d = np.squeeze(obj2_binary_nominal)\n",
    "\n",
    "# Manual calculation of Jaccard Similarity\n",
    "# M11: number of (1,1) matches\n",
    "m11 = np.sum((obj1_binary_nominal_1d == 1) & (obj2_binary_nominal_1d == 1))\n",
    "# M10: number of (1,0) mismatches (obj1 is 1, obj2 is 0)\n",
    "m10 = np.sum((obj1_binary_nominal_1d == 1) & (obj2_binary_nominal_1d == 0))\n",
    "# M01: number of (0,1) mismatches (obj1 is 0, obj2 is 1)\n",
    "m01 = np.sum((obj1_binary_nominal_1d == 0) & (obj2_binary_nominal_1d == 1))\n",
    "\n",
    "# Jaccard = M11 / (M10 + M01 + M11)\n",
    "denominator = m10 + m01 + m11\n",
    "jaccard = m11 / denominator if denominator != 0 else 0 # Handle division by zero\n",
    "\n",
    "print(f\"Jaccard Similarity: {jaccard:.4f}\")\n",
    "\n",
    "# Cosine Similarity\n",
    "# Cosine similarity is for numerical vectors.\n",
    "cosine_sim = cosine_similarity(obj1_numerical_cosine.reshape(1, -1), obj2_numerical_cosine.reshape(1, -1))[0][0]\n",
    "print(f\"Cosine Similarity: {cosine_sim:.4f}\")\n",
    "\n",
    "# (b) Calculate Correlation between two features Commute Distance and Yearly Income\n",
    "# As 'Commute Distance' is not directly present, we use 'NumberCarsOwned' as a proxy.\n",
    "# We will use the original columns for correlation before extensive one-hot encoding/binning for direct interpretation.\n",
    "# Load original data again to get un-transformed numerical columns\n",
    "df_original_numeric = df_merged[['NumberCarsOwned', 'YearlyIncome']].copy()\n",
    "\n",
    "# Handle potential nulls in these specific columns before correlation if any exist\n",
    "for col in ['NumberCarsOwned', 'YearlyIncome']:\n",
    "    if df_original_numeric[col].isnull().any():\n",
    "        df_original_numeric[col].fillna(df_original_numeric[col].median(), inplace=True)\n",
    "\n",
    "# Calculate Pearson correlation coefficient\n",
    "correlation, _ = pearsonr(df_original_numeric['NumberCarsOwned'], df_original_numeric['YearlyIncome'])\n",
    "print(f\"\\n--- Correlation Analysis ---\")\n",
    "print(f\"Pearson Correlation between 'NumberCarsOwned' (proxy for Commute Distance) and 'YearlyIncome': {correlation:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
