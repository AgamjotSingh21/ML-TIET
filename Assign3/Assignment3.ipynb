{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb38c8f-5aa2-4f78-b825-bfe8207e6305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset:\n",
      " Index(['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms',\n",
      "       'Avg. Area Number of Bedrooms', 'Area Population', 'Price'],\n",
      "      dtype='object')\n",
      "\n",
      "Sample data:\n",
      "    Avg. Area Income  Avg. Area House Age  Avg. Area Number of Rooms  \\\n",
      "0       79545.45857             5.682861                   7.009188   \n",
      "1       79248.64245             6.002900                   6.730821   \n",
      "2       61287.06718             5.865890                   8.512727   \n",
      "3       63345.24005             7.188236                   5.586729   \n",
      "4       59982.19723             5.040555                   7.839388   \n",
      "\n",
      "   Avg. Area Number of Bedrooms  Area Population         Price  \n",
      "0                          4.09      23086.80050  1.059034e+06  \n",
      "1                          3.09      40173.07217  1.505891e+06  \n",
      "2                          5.13      36882.15940  1.058988e+06  \n",
      "3                          3.26      34310.24283  1.260617e+06  \n",
      "4                          4.23      26354.10947  6.309435e+05  \n",
      "\n",
      "Q1 - R² scores for 5 folds: [0.9179971706985147, 0.9145677884802818, 0.9116116385364478, 0.9193091764960817, 0.9243869413350316]\n",
      "Q1 - Best Beta (coefficients): [1.23161736e+06 2.30225051e+05 1.63956839e+05 1.21115120e+05\n",
      " 7.83467170e+02 1.50662447e+05]\n",
      "Q1 - Final Test R² score (70/30 split): 0.9146818498916266\n",
      "\n",
      "Q2 - Gradient Descent Results:\n",
      "LR=0.001 | Validation R²=-0.8125 | Test R²=-0.9914\n",
      "LR=0.01 | Validation R²=0.9098 | Test R²=0.9147\n",
      "LR=0.1 | Validation R²=0.9098 | Test R²=0.9148\n",
      "LR=1 | Validation R²=0.9098 | Test R²=0.9148\n",
      "\n",
      "Q2 - Best Learning Rate: 0.01\n",
      "Q2 - Best Beta (coefficients): [1232562.51254919  230048.76664688  163686.93503606  121406.94107918\n",
      "    3117.47363933  150655.97459714]\n",
      "Q2 - Best Validation R²: 0.9098183094422969\n",
      "Q2 - Corresponding Test R²: 0.9147434800538763\n",
      "Performance without PCA:\n",
      "  R2: 0.7895045576733848\n",
      "  MSE: 14448999.01183785\n",
      "  MAE: 2653.9312500465594\n",
      "\n",
      "Performance with PCA:\n",
      "  R2: 0.7478420860380316\n",
      "  MSE: 17308828.2073597\n",
      "  MAE: 2954.104165203941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_222792\\2629609782.py:135: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"num_doors\"] = df[\"num_doors\"].replace(word_to_num)\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_222792\\2629609782.py:136: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"num_cylinders\"] = df[\"num_cylinders\"].replace(word_to_num)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# LOAD DATASET\n",
    "df = pd.read_csv('USA_Housing.csv')\n",
    "\n",
    "# Print first few rows & column names to inspect\n",
    "print(\"Columns in dataset:\\n\", df.columns)\n",
    "print(\"\\nSample data:\\n\", df.head())\n",
    "\n",
    "# --- Detect the target column automatically ---\n",
    "target_candidates = [c for c in df.columns if 'price' in c.lower()]\n",
    "if len(target_candidates) == 0:\n",
    "    raise ValueError(\"No column containing 'price' found. Please check dataset columns!\")\n",
    "target_col = target_candidates[0]\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(target_col, axis=1).values\n",
    "y = df[target_col].values.reshape(-1, 1)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Q1: 5-FOLD CROSS VALIDATION (LEAST SQUARE ERROR FIT)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "r2_scores = []\n",
    "betas = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    X_train_aug = np.hstack([np.ones((X_train.shape[0], 1)), X_train])\n",
    "    X_test_aug = np.hstack([np.ones((X_test.shape[0], 1)), X_test])\n",
    "\n",
    "    beta = np.linalg.inv(X_train_aug.T @ X_train_aug) @ X_train_aug.T @ y_train\n",
    "    y_pred = X_test_aug @ beta\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores.append(r2)\n",
    "    betas.append(beta)\n",
    "\n",
    "best_beta = betas[np.argmax(r2_scores)]\n",
    "print(\"\\nQ1 - R² scores for 5 folds:\", r2_scores)\n",
    "print(\"Q1 - Best Beta (coefficients):\", best_beta.ravel())\n",
    "\n",
    "# Retrain using best beta on 70%-30% split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "X_train_aug = np.hstack([np.ones((X_train.shape[0], 1)), X_train])\n",
    "X_test_aug = np.hstack([np.ones((X_test.shape[0], 1)), X_test])\n",
    "beta_final = np.linalg.inv(X_train_aug.T @ X_train_aug) @ X_train_aug.T @ y_train\n",
    "y_pred_final = X_test_aug @ beta_final\n",
    "print(\"Q1 - Final Test R² score (70/30 split):\", r2_score(y_test, y_pred_final))\n",
    "\n",
    "# Q2: VALIDATION SET APPROACH (GRADIENT DESCENT)\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_aug = np.hstack([np.ones((X_train.shape[0], 1)), X_train])\n",
    "X_val_aug = np.hstack([np.ones((X_val.shape[0], 1)), X_val])\n",
    "X_test_aug = np.hstack([np.ones((X_test.shape[0], 1)), X_test])\n",
    "\n",
    "def gradient_descent(X, y, lr, iterations=1000):\n",
    "    m, n = X.shape\n",
    "    beta = np.zeros((n, 1))\n",
    "    for i in range(iterations):\n",
    "        gradient = (1/m) * (X.T @ (X @ beta - y))\n",
    "        beta -= lr * gradient\n",
    "    return beta\n",
    "\n",
    "learning_rates = [0.001, 0.01, 0.1, 1]\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    beta_gd = gradient_descent(X_train_aug, y_train, lr)\n",
    "    y_val_pred = X_val_aug @ beta_gd\n",
    "    y_test_pred = X_test_aug @ beta_gd\n",
    "    r2_val = r2_score(y_val, y_val_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    results.append((lr, beta_gd, r2_val, r2_test))\n",
    "\n",
    "best_lr, best_beta_gd, best_val_r2, best_test_r2 = max(results, key=lambda x: x[2])\n",
    "print(\"\\nQ2 - Gradient Descent Results:\")\n",
    "for lr, beta_gd, r2_val, r2_test in results:\n",
    "    print(f\"LR={lr} | Validation R²={r2_val:.4f} | Test R²={r2_test:.4f}\")\n",
    "print(\"\\nQ2 - Best Learning Rate:\", best_lr)\n",
    "print(\"Q2 - Best Beta (coefficients):\", best_beta_gd.ravel())\n",
    "print(\"Q2 - Best Validation R²:\", best_val_r2)\n",
    "print(\"Q2 - Corresponding Test R²:\", best_test_r2)\n",
    "\n",
    "# Q3: Pre-processing and Multiple Linear Regression\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# 1. Load dataset\n",
    "columns = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\n",
    "           \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\", \"wheel_base\",\n",
    "           \"length\", \"width\", \"height\", \"curb_weight\", \"engine_type\", \"num_cylinders\",\n",
    "           \"engine_size\", \"fuel_system\", \"bore\", \"stroke\", \"compression_ratio\",\n",
    "           \"horsepower\", \"peak_rpm\", \"city_mpg\", \"highway_mpg\", \"price\"]\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
    "df = pd.read_csv(url, names=columns)\n",
    "\n",
    "# 2. Replace ? with NaN, impute missing values\n",
    "df = df.replace(\"?\", np.nan)\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])  # categorical: mode\n",
    "    else:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        df[col] = df[col].fillna(df[col].median())   # numeric: median\n",
    "\n",
    "df = df.dropna(subset=[\"price\"])  # drop rows with missing price\n",
    "df[\"price\"] = pd.to_numeric(df[\"price\"])\n",
    "\n",
    "# 3. Encoding\n",
    "# (i) num_doors & num_cylinders\n",
    "word_to_num = {\"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5, \"six\": 6,\n",
    "               \"eight\": 8, \"twelve\": 12}\n",
    "df[\"num_doors\"] = df[\"num_doors\"].replace(word_to_num)\n",
    "df[\"num_cylinders\"] = df[\"num_cylinders\"].replace(word_to_num)\n",
    "\n",
    "df[\"num_doors\"] = pd.to_numeric(df[\"num_doors\"], errors=\"coerce\").astype(int)\n",
    "df[\"num_cylinders\"] = pd.to_numeric(df[\"num_cylinders\"], errors=\"coerce\").astype(int)\n",
    "\n",
    "# (ii) body_style & drive_wheels → dummy encoding\n",
    "df = pd.get_dummies(df, columns=[\"body_style\", \"drive_wheels\"], drop_first=True)\n",
    "\n",
    "# (iii) make, aspiration, engine_location, fuel_type → label encoding\n",
    "label_cols = [\"make\", \"aspiration\", \"engine_location\", \"fuel_type\"]\n",
    "le = LabelEncoder()\n",
    "for col in label_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# (iv) fuel_system → pfi = 1 else 0\n",
    "df[\"fuel_system\"] = df[\"fuel_system\"].apply(lambda x: 1 if \"pfi\" in x else 0)\n",
    "\n",
    "# (v) engine_type → ohc = 1 else 0\n",
    "df[\"engine_type\"] = df[\"engine_type\"].apply(lambda x: 1 if \"ohc\" in x else 0)\n",
    "\n",
    "# 4. Split features & target\n",
    "X = df.drop(\"price\", axis=1)\n",
    "y = df[\"price\"]\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 5. Train-test split (70-30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(\"Performance without PCA:\")\n",
    "print(\"  R2:\", r2_score(y_test, y_pred))\n",
    "print(\"  MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"  MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "# 6. PCA + Linear Regression\n",
    "pca = PCA(n_components=0.95)  # keep 95% variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
    "\n",
    "lr_pca = LinearRegression()\n",
    "lr_pca.fit(X_train_pca, y_train_pca)\n",
    "y_pred_pca = lr_pca.predict(X_test_pca)\n",
    "\n",
    "print(\"\\nPerformance with PCA:\")\n",
    "print(\"  R2:\", r2_score(y_test_pca, y_pred_pca))\n",
    "print(\"  MSE:\", mean_squared_error(y_test_pca, y_pred_pca))\n",
    "print(\"  MAE:\", mean_absolute_error(y_test_pca, y_pred_pca))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
